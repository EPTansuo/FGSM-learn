{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cca3cc6-4a9c-43a7-8198-c24925ebebba",
   "metadata": {},
   "source": [
    "# Caltech101 分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ac7e8-749f-472d-9122-842367625e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from six.moves import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45268f3f-9164-471b-9163-ca22abdaada4",
   "metadata": {},
   "source": [
    "这个数据集下载连接为google drive，无法直接从torchvision.datasets下载，可手动下载解压到指定文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079a18d-58bf-456e-8a5b-a6e349a3815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    #transforms.ToPILImage(),\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean = [0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 下载并加载Caltech101数据集\n",
    "caltech101_dataset = torchvision.datasets.Caltech101(\n",
    "    root='./data',\n",
    "    download=False,  # 设置为True以从互联网下载数据集\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f'总数据集大小：{len(caltech101_dataset)}')\n",
    "\n",
    "# 定义训练和测试集的大小\n",
    "train_size = int(0.8 * len(caltech101_dataset))  # 例如，80%为训练集\n",
    "test_size = len(caltech101_dataset) - train_size  # 剩余20%为测试集\n",
    "print(f\"train_size: {train_size}, test_size: {test_size}\");\n",
    "train_data,test_data = torch.utils.data.random_split(caltech101_dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    #print(images.size(), labels)\n",
    "    break;\n",
    "    \n",
    "\n",
    "print(images[0].numpy().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20157a9-2fa6-4ecd-8e5d-6904c5786c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "caltech101_dataset.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ad616-d985-4309-b258-e39ee5284e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_show(imgs,labs=[]):\n",
    "    i=0\n",
    "    h=math.ceil(len(imgs)/2)\n",
    "  \n",
    "    \n",
    "    for img in imgs:\n",
    "        img = img / 2 + 0.5  \n",
    "        npimg = img.numpy()\n",
    "        plt.subplot(2,h,i+1)\n",
    "        if labs != []:\n",
    "            plt.title(caltech101_dataset.categories[labs[i]])\n",
    "        plt.imshow((np.transpose(npimg, (1, 2, 0))))\n",
    "        #print(npimg.shape)\n",
    "        i+=1\n",
    "        #plt.imshow(npimg)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48bf971-bfe4-4ac6-8c61-96c7bdfb95dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_show(images,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ff89c-50bd-4e79-8ad4-0ea129efb7c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pretrainedmodels\n",
    "\n",
    "# the resnet34 model\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(ResNet34, self).__init__()\n",
    "        if pretrained is True:\n",
    "            self.model = pretrainedmodels.__dict__['resnet34'](pretrained='imagenet')\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__['resnet34'](pretrained = None)\n",
    "        # change the classification layer\n",
    "        self.l0= nn.Linear(512, len(caltech101_dataset.categories))\n",
    "        self.dropout = nn.Dropout2d(0.4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # get the batch size only, ignore(c, h, w)\n",
    "        batch, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n",
    "        x = self.dropout(x)\n",
    "        l0 = self.l0(x)\n",
    "        return l0\n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # GPU\n",
    "#device = \"cpu\"\n",
    "model = ResNet34(pretrained=True).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896bf61-b7b9-4329-9e04-6d0572534ef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "print(summary(model, input_size=(3, 224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73443cf-d191-4c49-b5ac-e72064b1ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d658fdf-ce28-4820-85b0-ad73af2eb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "\n",
    "epochs = 20 # Number of epochs\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46111181-0023-424b-8bce-f2aa8415ec20",
   "metadata": {},
   "source": [
    "# 保存权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86876663-f164-40f4-852e-fb1ed953baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PATH = './caltech101_net.pth'\n",
    "#torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f980439-c0c8-4942-b3b8-a7031ffb981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "images_show(images,labels)\n",
    "#print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7a139-0a52-4d83-aa28-f4769285cfaa",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db2c50-c4a8-40e9-ba42-42c45b22313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "PATH = './caltech101_net.pth'\n",
    "net = ResNet34(False)\n",
    "if device == \"cpu\":\n",
    "    net.load_state_dict(torch.load(PATH, map_location='cpu'))\n",
    "else:\n",
    "    net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b39f1-ca7a-4fd2-ae3b-5f65d196b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "outputs = net(images)\n",
    "print(images.shape)\n",
    "#print(outputs)\n",
    "#for i in range(outputs):\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print(predicted)\n",
    "for j in range(8):\n",
    "    plt.subplot(1,2,1)\n",
    "    for i in range(101):\n",
    "        plt.bar(i,outputs[j][i].item())\n",
    "    plt.title(caltech101_dataset.categories[predicted[j]])\n",
    "    plt.subplot(1,2,2)\n",
    "\n",
    "    img = images[j] / 2 + 0.5  \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow((np.transpose(npimg, (1, 2, 0))))\n",
    "    plt.title(caltech101_dataset.categories[labels[j]])\n",
    "    plt.savefig(f'./fig/{j}.svg')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd8b90-5850-43ca-9f16-4b3c527b5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e33a5-dd9d-4b1e-89be-8e44ec76ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in caltech101_dataset.categories}\n",
    "total_pred = {classname: 0 for classname in caltech101_dataset.categories}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[caltech101_dataset.categories[label]] += 1\n",
    "            total_pred[caltech101_dataset.categories[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172fcdb-3c37-4925-a2b3-f74a2f64ba64",
   "metadata": {},
   "source": [
    "参考：\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "https://colab.research.google.com/github/ashishpatel26/Awesome-Pytorch-Tutorials/blob/main/17.Pytorch%20Transfer%20learning%20with%20Caltech101.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517862cf-ffa2-43df-bb02-7a97ce50af88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
