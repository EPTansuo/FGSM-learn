


%matplotlib inline
%config InlineBackend.figure_format = 'svg'
import os
import torch
import torchvision
import torchvision.transforms as transforms
from sklearn.preprocessing import LabelEncoder
from six.moves import urllib
import matplotlib.pyplot as plt
import numpy as np
import math


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") # GPU
#device = "cpu"

classes = [
    'Faces', 'Faces_easy', 'Leopards', 'Motorbikes', 'accordion', 'airplanes', 
    'anchor', 'ant', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 
    'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 
    'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 
    'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 
    'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 
    'euphonium', 'ewer', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 
    'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 
    'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 
    'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 
    'minaret', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 
    'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 
    'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 
    'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 
    'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 
    'wild_cat', 'windsor_chair', 'wrench', 'yin_yang'
]
len(classes)


import torch.nn as nn
import torch.nn.functional as F
import pretrainedmodels

# the resnet34 model
class ResNet34(nn.Module):
    def __init__(self, pretrained):
        super(ResNet34, self).__init__()
        if pretrained is True:
            self.model = pretrainedmodels.__dict__['resnet34'](pretrained='imagenet')
        else:
            self.model = pretrainedmodels.__dict__['resnet34'](pretrained = None)
        # change the classification layer
        self.l0= nn.Linear(512, len(classes))
        self.dropout = nn.Dropout2d(0.4)
        
    def forward(self, x):
        # get the batch size only, ignore(c, h, w)
        batch, _, _, _ = x.shape
        x = self.model.features(x)
        x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)
        x = self.dropout(x)
        l0 = self.l0(x)
        return l0


PATH = '../Classify/caltech101_net.pth'
net = ResNet34(False).to(device)
if device == "cpu":
    net.load_state_dict(torch.load(PATH, map_location='cpu'))
else:
    net.load_state_dict(torch.load(PATH))

net.eval()


def imshow(outputs,images,ifSave=False,savePath=""):
    plt.subplot(1,2,1)
    for i in range(101):
        plt.bar(i,outputs[0][i].item())
    _, predicted = torch.max(outputs, 1)
    plt.title(classes[predicted.item()],fontdict={"weight": "normal", "size": 20})
    plt.subplot(1,2,2)
    img = images / 2 + 0.5  
    npimg = img.detach().cpu().numpy()
    plt.imshow((np.transpose(npimg[0], (1, 2, 0))))
    if ifSave:
        plt.savefig(savePath)
    plt.show()

def showPertabation(pertabation,ifSave=False,savePath=""):
    plt.imshow(np.transpose(
            torchvision.utils.make_grid(
                pertabation.cpu().data, normalize=True
            ).numpy(),(1,2,0)))
    if ifSave:
        plt.savefig(savePath)
    plt.show()



from PIL import Image

transform = transforms.Compose([
    transforms.Lambda(lambda x: x.convert("RGB")),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

img = Image.open("./img/an225.jpg")
image = transform(img)
images = image.unsqueeze(0)
label = torch.tensor(classes.index("airplanes"))
labels = label.unsqueeze(0)


outputs = net(images.to(device))
_, predicted = torch.max(outputs, 1)
classes[predicted.item()]

imshow(outputs, images, ifSave = True, savePath = './out/before.svg')


eps = 0.01


def fgsm(net, loss, images, labels, eps):
    images = images.clone().detach().to(device).requires_grad_(True)
    labels = labels.to(device)
    outputs = net(images)
    net.zero_grad()
    cost = loss(outputs, labels).to(device)
    cost.backward()
    pertabation = eps*images.grad.sign()
    attack_images = images + pertabation
    attack_images = torch.clamp(attack_images, -1,1)
    
    return attack_images, pertabation


eps=0.01
loss = nn.CrossEntropyLoss()
images_before = images.to(device)
images_after, pertabation = fgsm(net, loss, images, labels, eps)
images_after = images_after.to(device)
labels = labels.to(device)
outputs = net(images_after)

_, pre = torch.max(outputs.data,1)

imshow(outputs, images_after, ifSave = True, savePath = './out/after.svg')

showPertabation(pertabation, ifSave = True, savePath = './out/pertabation.png')



def ifgsm(net, loss, images, labels, eps, iteration):

    images = images.to(device)
    labels = labels.to(device)
    #images = images.detach()
    #images.requires_grad = True

    images_adv = images.data.clone().detach().requires_grad_(True).to(device)

    
    
    for i in range(iteration):
        print(f'iteration: {i+1}')
        outputs = net(images_adv)
        net.zero_grad()
        if images_adv.grad is not None:
            images_adv.grad.data.fill_(0)
        cost = loss(outputs, labels).to(device)
        cost.backward()
        pertabation = eps*images_adv.grad.sign()
        images_adv = images_adv + pertabation
        images_adv = torch.where(images_adv > images_adv+eps, images_adv+eps, images_adv)
        images_adv = torch.where(images_adv < images_adv-eps, images_adv-eps, images_adv)
        images_adv = torch.clamp(images_adv, -1,1)

        # 重置images_adv的梯度，以便于下一次迭代
        images_adv = images_adv.data.clone().detach().requires_grad_(True).to(device)

        
    pertation_all = images_adv - images
    
    return images_adv, pertation_all


loss = nn.CrossEntropyLoss()
images_before = images
eps = 0.001
images_after, pertabation = ifgsm(net, loss, images, labels, eps,10)
images_after = images_after.to(device)
labels = labels.to(device)
outputs = net(images_after)

_, pre = torch.max(outputs.data,1)



imshow(outputs, images_after, ifSave = True, savePath = './out/iter_after.svg')

showPertabation(pertabation, ifSave = True, savePath = './out/iter_pertabation.png')



def ifgsm_targeted(net, loss, images, eps, iteration,targets):

    images = images.to(device)
    targets = targets.to(device)

    images_adv = images.data.clone().detach().requires_grad_(True).to(device)
    
    for i in range(iteration):
        print(f'iteration: {i+1}')
        outputs = net(images_adv)
        net.zero_grad()
        #if images_adv.grad is not None:
            #images_adv.grad.data.fill_(0)
        cost = loss(outputs, targets).to(device)
        cost.backward()
        pertabation = eps*images_adv.grad.sign()
        images_adv = images_adv - pertabation
        images_adv = torch.where(images_adv > images_adv+eps, images_adv+eps, images_adv)
        images_adv = torch.where(images_adv < images_adv-eps, images_adv-eps, images_adv)
        images_adv = torch.clamp(images_adv, -1,1)

        # 重置images_adv的梯度，以便于下一次迭代
        images_adv = images_adv.data.clone().detach().requires_grad_(True).to(device)

        
    pertation_all = images_adv - images
    
    return images_adv, pertation_all


loss = nn.CrossEntropyLoss()
images_before = images
eps = 0.005
target = torch.tensor(classes.index("dragonfly"))
targets = target.unsqueeze(0)
images_after, pertabation = ifgsm_targeted(net, loss, images, eps,10,targets)
images_after = images_after.to(device)
labels = labels.to(device)
outputs = net(images_after)

_, pre = torch.max(outputs.data,1)


imshow(outputs, images_after, ifSave = True, savePath = './out/iter_after_targeted.svg')

showPertabation(pertabation, ifSave = True, savePath = './out/iter_pertabation_targeted.png')



